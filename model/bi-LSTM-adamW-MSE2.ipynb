{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jMkgfO443DF6"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRIlGFk2_z0",
        "outputId": "38c8222e-31a0-4c6c-ee00-a6abcff0bdca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bobby\\anaconda3\\envs\\research\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "c:\\Users\\bobby\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Input, TimeDistributed, RepeatVector, Dense\n",
        "from tensorflow.keras.layers import Bidirectional, \\\n",
        "    multiply, concatenate, Flatten, Activation, dot\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "import keras\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "mae, rmse, r2 = mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# !pip install tensorflow_addons==0.16.1\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.optimizers import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W_OeNEX43N-u"
      },
      "outputs": [],
      "source": [
        "def readdata(inputcsv, outputcsv):\n",
        "\n",
        "    idx = pd.IndexSlice\n",
        "    input_data2 = pd.read_csv(inputcsv, index_col=[0], header=[0,1])\n",
        "    input_data2.index = pd.to_datetime(input_data2.index)\n",
        "    input_data2.columns = input_data2.columns.set_levels(input_data2.columns.levels[0].astype('int64'), level=0)\n",
        "    input_data2.columns = input_data2.columns.set_levels(input_data2.columns.levels[1].astype('string'), level=1)\n",
        "\n",
        "    ground_truth2 = pd.read_csv(outputcsv, index_col=[0], header=[0,1])\n",
        "    ground_truth2.index = pd.to_datetime(ground_truth2.index)\n",
        "    ground_truth2.columns = ground_truth2.columns.set_levels(ground_truth2.columns.levels[0].astype('int64'), level=0)\n",
        "    ground_truth2.columns = ground_truth2.columns.set_levels(ground_truth2.columns.levels[1].astype('string'), level=1)\n",
        "\n",
        "    log_transform = lambda x: np.log10(x+1) if x.name[1] == 'tp' else x\n",
        "    input_data2 = input_data2.apply(log_transform)\n",
        "    ground_truth2 = ground_truth2.apply(log_transform)\n",
        "\n",
        "    scaledx = MinMaxScaler()\n",
        "    scaled_input = scaledx.fit_transform(input_data2.values)\n",
        "    scaled_input_df = pd.DataFrame(scaled_input, index=input_data2.index, columns=input_data2.columns)\n",
        "\n",
        "    scaledy = MinMaxScaler()\n",
        "    scaled_ground = scaledy.fit_transform(ground_truth2.values)\n",
        "    scaled_ground_df = pd.DataFrame(scaled_ground, index=ground_truth2.index, columns=ground_truth2.columns)\n",
        "\n",
        "    frames = [scaled_input_df, scaled_ground_df]\n",
        "    dataset = pd.concat(frames, axis=1)\n",
        "\n",
        "    train_dataset = dataset.loc['2000-01-01':'2016-12-31']\n",
        "    test_dataset = dataset.loc['2017-01-01':'2019-12-31']\n",
        "\n",
        "    return train_dataset, test_dataset, scaledx, scaledy\n",
        "\n",
        "train_dataset, test_dataset, scaledx, scaledy = readdata('input_data3.csv', 'ground_truth3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eK4tpT9v3ale"
      },
      "outputs": [],
      "source": [
        "date_index = pd.date_range('2000-01-01','2016-12-22',freq='D') # changed to 2000-01-01 from 2000-01-10\n",
        "break_index = [0]+[list(date_index).index(pd.to_datetime('%s-12-31'%year))+1\n",
        " for year in range(2000,2016)] + [len(date_index)]\n",
        "\n",
        "def split_by_year(freq_year, break_index):\n",
        "    # freq_year = 2\n",
        "    end_index = 0\n",
        "    tscv = []\n",
        "    while True:\n",
        "        start_index = end_index\n",
        "        if start_index + freq_year >= len(break_index):\n",
        "            break\n",
        "        end_index = min(start_index+2*freq_year, len(break_index)-1)\n",
        "        tscv.append((list(range(break_index[start_index],break_index[start_index+freq_year])),\n",
        "                     list(range(break_index[start_index+freq_year],break_index[end_index]))))\n",
        "    return tscv\n",
        "\n",
        "freq_year = 2 # freq_year < total year/2  # 2000-2001 (2 years) test 2 years x4\n",
        "tscv = split_by_year(freq_year, break_index)\n",
        "\n",
        "def get_xy(series, time_step, n_feature):\n",
        "    x = series.iloc[:,:-1].T.unstack(level=0).T.values.reshape(len(series),time_step,n_feature) # time_step will be 10\n",
        "    y = pd.concat([series.iloc[:,-1].shift(-i) for i in range(time_step)], axis=1).dropna(axis=0, how='any').values\n",
        "    y = y.reshape(y.shape[0],y.shape[1],1)\n",
        "    x = x[:y.shape[0],:,:]\n",
        "    return x, y\n",
        "\n",
        "time_step, n_features = 10, 5\n",
        "train_x, train_y = get_xy(train_dataset, time_step, n_features)\n",
        "test_x, test_y = get_xy(test_dataset, time_step, n_features)\n",
        "\n",
        "input_train = Input(shape=(train_x.shape[1], train_x.shape[2]))\n",
        "output_train = Input(shape=(train_y.shape[1], train_y.shape[2]))\n",
        "\n",
        "# gridsearchCV does not take in 3D shape as inputs, only 2D\n",
        "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1]*train_x.shape[2])\n",
        "train_y = train_y.reshape(train_y.shape[0], train_y.shape[1]*train_y.shape[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uJOMDjdM3tKJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_math_ops import square\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Loss function with weights based on amplitude of y_true\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def my_MSE_weighted2(y_true,y_pred):\n",
        "    return K.mean(tf.multiply(tf.exp(tf.multiply(2.0, y_true)), tf.square(tf.subtract(y_pred, y_true))))\n",
        "\n",
        "# def my_MSE_weighted2_5(y_true,y_pred):\n",
        "#     return K.mean(tf.multiply(tf.exp(tf.multiply(2.5, y_true)), tf.square(tf.subtract(y_pred, y_true))))\n",
        "\n",
        "# def my_MSE_weighted3(y_true,y_pred):\n",
        "#     return K.mean(tf.multiply(tf.exp(tf.multiply(3.0, y_true)), tf.square(tf.subtract(y_pred, y_true))))\n",
        "\n",
        "# scoring\n",
        "def my_custom_eval_func(y_true, y_pred):\n",
        "    # Remove 3D array warning\n",
        "    if len(y_pred.shape) == 3:\n",
        "        y_pred = y_pred.reshape(y_pred.shape[:-1])\n",
        "    return rmse(y_true, y_pred, squared=False)\n",
        "\n",
        "myenvEstimator  = make_scorer(my_custom_eval_func, greater_is_better=False)\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "class mylstm(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_steps=10, n_features=5,\n",
        "                 activation='relu', optimizer='adam',loss=my_MSE_weighted2,\n",
        "                 lstm=48, dense=1, verbose=1,\n",
        "                 epochs=20, batch_size=8):\n",
        "                 #learning_rate=1e-3, #weight_decay=1e-5):\n",
        "\n",
        "        # static parameters\n",
        "        self.n_steps = n_steps\n",
        "        self.n_features = n_features\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # Parameters that can be optimized\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "        self.lstm = lstm\n",
        "        self.dense = dense\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        #---------- luong attention ----------------\n",
        "        encoder_stack_h, encoder_forward_h, encoder_forward_c, encoder_backward_h, encoder_backward_c = Bidirectional(LSTM(self.lstm, activation=self.activation,\n",
        "                                                                                                                           return_state=True, return_sequences=True))(input_train)\n",
        "        encoder_last_h = concatenate([encoder_forward_h, encoder_backward_h])\n",
        "        encoder_last_c = concatenate([encoder_forward_c, encoder_backward_c])\n",
        "\n",
        "        decoder_input = RepeatVector(output_train.shape[1])(encoder_last_h)\n",
        "        decoder_stack_h = LSTM(self.lstm*2, activation=self.activation, return_state=False, return_sequences=True)(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
        "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2])\n",
        "        attention = Activation('softmax')(attention)\n",
        "        context = dot([attention, encoder_stack_h], axes=[2,1])\n",
        "        decoder_combined_context = concatenate([context, decoder_stack_h])\n",
        "        out = TimeDistributed(Dense(output_train.shape[2]))(decoder_combined_context)\n",
        "        self.model = Model(inputs=input_train, outputs=out)\n",
        "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
        "\n",
        "    def fit(self, X, y, **kw):\n",
        "        X = X.reshape(X.shape[0], self.n_steps, self.n_features)\n",
        "\n",
        "        # Control display output, If parameter `verbose` is given, it will be used.\n",
        "        # If no `verbose` is given, the default value of the class is used.\n",
        "        if 'verbose' in kw.keys():\n",
        "            return self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, **kw)\n",
        "        else:\n",
        "            return self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, **kw)\n",
        "\n",
        "\n",
        "    def predict(self, X, **kw):\n",
        "        X = X.reshape(X.shape[0], self.n_steps, self.n_features)\n",
        "\n",
        "        if 'verbose' in kw.keys():\n",
        "            return self.model.predict(X, **kw)\n",
        "        else:\n",
        "            return self.model.predict(X, verbose=self.verbose, **kw)\n",
        "\n",
        "    def score(self, X, y, **kw):\n",
        "        X = X.reshape(X.shape[0], self.n_steps, self.n_features)\n",
        "\n",
        "        # Control display output\n",
        "        if 'verbose' in kw.keys():\n",
        "            return self.model.evaluate(X, y, **kw)\n",
        "        else:\n",
        "            return self.model.evaluate(X, y, verbose=self.verbose, **kw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9r0XHLX4ARW",
        "outputId": "187d19b0-51b0-47c7-be15-9666beba9d57"
      },
      "outputs": [],
      "source": [
        "# lr_schedule = tf.optimizers.schedules.ExponentialDecay(1e-3, 24, 0.95) # every 2 epochs\n",
        "# wd_schedule = tf.optimizers.schedules.ExponentialDecay(1e-5, 24, 0.95)\n",
        "# opt = AdamW(learning_rate=lr_schedule, weight_decay=lambda : None)\n",
        "# opt.weight_decay = lambda : wd_schedule(opt.iterations)\n",
        "opt = Adam(learning_rate=1e-4)\n",
        "\n",
        "# parameters = {'activation':('relu', 'sigmoid', 'tanh'), 'lstm':[48,64,80], 'loss':(my_MSE_weighted, 'mse')} # Actual calculation\n",
        "parameters = {'activation':('relu','tanh'), 'lstm':[32,48,64,80,100,128,144,160], 'loss':(my_MSE_weighted2, 'mse')} # Actual calculation\n",
        "# parameters = {'activation':('relu','tanh')} # Actual calculation\n",
        "# parameters = {} # original parameters\n",
        "\n",
        "tscv = split_by_year(freq_year, break_index)\n",
        "clf = GridSearchCV(mylstm(verbose=1, epochs=20, batch_size=8, optimizer=opt), parameters, cv=tscv, scoring=myenvEstimator)\n",
        "# clf = GridSearchCV(mylstm(verbose=1, epochs=30, batch_size=64, optimizer=optimizer, parameters, cv=tscv, scoring=myenvEstimator))\n",
        "\n",
        "clf.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyFSh9MI4JTE"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(clf.cv_results_)\n",
        "results_df['mean_test_score'] = results_df['mean_test_score'].abs()\n",
        "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
        "results_df = results_df.set_index(\n",
        "    results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
        ").rename_axis(\"kernel\")\n",
        "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]\n",
        "\n",
        "model_df = results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]\n",
        "# model_df.to_csv('tunings_mse2_biadam.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcjqrcMu98Se",
        "outputId": "326d5bfa-ee73-44b4-cff3-b7a3d8276ecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([48.25649691, 35.09181929, 35.86329842, 35.25014049, 36.32160974,\n",
              "        39.80626363, 40.09244198, 38.76100546, 39.58778954, 41.10896057,\n",
              "        42.42620128, 43.13410336, 44.47147024, 44.06862843, 44.73675287,\n",
              "        43.60585213, 56.02843034, 45.176467  , 56.78962451, 56.74436426,\n",
              "        47.26439083, 57.05959105, 48.17155099, 48.85460126, 68.1179077 ,\n",
              "        59.80541694, 59.39382249, 77.48450124, 59.83895636, 68.34578526,\n",
              "        59.75040925, 59.13266689]),\n",
              " 'mean_score_time': array([0.75094962, 0.68144286, 0.72104585, 0.8548755 , 0.70880604,\n",
              "        0.78209698, 0.76868701, 0.73193061, 0.71389496, 0.75992006,\n",
              "        0.73628891, 0.76536262, 1.02915251, 0.91230369, 0.82881784,\n",
              "        0.77171475, 0.79725552, 0.93370324, 0.82907778, 0.78102207,\n",
              "        0.84719265, 0.79590333, 0.85109013, 0.80885816, 0.82633185,\n",
              "        0.74711382, 0.78590304, 0.94416595, 0.82948768, 0.88558722,\n",
              "        0.95583731, 0.76971895]),\n",
              " 'mean_test_score': array([-0.17140935, -0.16946278, -0.17191349, -0.17120344, -0.17098864,\n",
              "        -0.17155169, -0.1703691 , -0.17031134, -0.17132072, -0.17110455,\n",
              "        -0.17062835, -0.17159526, -0.17047657, -0.17168916, -0.17094317,\n",
              "        -0.17063748, -0.17124836, -0.17069685, -0.17105148, -0.17246263,\n",
              "        -0.1709784 , -0.17118051, -0.17195347, -0.17260508, -0.17077191,\n",
              "        -0.17032812, -0.1709182 , -0.17142331, -0.17104466, -0.17216353,\n",
              "        -0.1712121 , -0.17127744]),\n",
              " 'param_activation': masked_array(data=['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=[<function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>, 'mse',\n",
              "                    'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse',\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>,\n",
              "                    <function my_MSE_weighted2 at 0x7f418c210a70>, 'mse',\n",
              "                    'mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'mse'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_lstm': masked_array(data=[32, 48, 64, 80, 100, 128, 144, 160, 32, 48, 64, 80,\n",
              "                    100, 128, 144, 160, 32, 48, 64, 80, 100, 128, 144, 160,\n",
              "                    32, 48, 64, 80, 100, 128, 144, 160],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 32},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 48},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 64},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 80},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 100},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 128},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 144},\n",
              "  {'activation': 'relu',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 160},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 32},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 48},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 64},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 80},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 100},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 128},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 144},\n",
              "  {'activation': 'relu', 'loss': 'mse', 'lstm': 160},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 32},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 48},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 64},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 80},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 100},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 128},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 144},\n",
              "  {'activation': 'tanh',\n",
              "   'loss': <function __main__.my_MSE_weighted2>,\n",
              "   'lstm': 160},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 32},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 48},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 64},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 80},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 100},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 128},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 144},\n",
              "  {'activation': 'tanh', 'loss': 'mse', 'lstm': 160}],\n",
              " 'rank_test_score': array([23,  1, 28, 18, 13, 25,  4,  2, 22, 16,  6, 26,  5, 27, 11,  7, 20,\n",
              "         8, 15, 31, 12, 17, 29, 32,  9,  3, 10, 24, 14, 30, 19, 21],\n",
              "       dtype=int32),\n",
              " 'split0_test_score': array([-0.15736037, -0.15465162, -0.15660644, -0.15544768, -0.15653382,\n",
              "        -0.15617891, -0.15476529, -0.15496171, -0.15781659, -0.15699332,\n",
              "        -0.15587   , -0.1563561 , -0.15702696, -0.15685038, -0.15707761,\n",
              "        -0.15568924, -0.1553528 , -0.15670911, -0.15649655, -0.1573983 ,\n",
              "        -0.15623663, -0.15628862, -0.15608992, -0.15729449, -0.15580183,\n",
              "        -0.15641691, -0.15658377, -0.15549015, -0.15637872, -0.15726112,\n",
              "        -0.15614527, -0.15654619]),\n",
              " 'split1_test_score': array([-0.16423658, -0.16134857, -0.16260877, -0.16321845, -0.16289693,\n",
              "        -0.16429865, -0.16052987, -0.16328015, -0.16289861, -0.16424274,\n",
              "        -0.16194532, -0.16360664, -0.16406043, -0.16443796, -0.16257938,\n",
              "        -0.1634551 , -0.16409266, -0.16454183, -0.16317288, -0.16328713,\n",
              "        -0.1655104 , -0.16409952, -0.16417448, -0.16460634, -0.16313489,\n",
              "        -0.16403792, -0.16283831, -0.16378156, -0.16220745, -0.16461922,\n",
              "        -0.16225763, -0.16283127]),\n",
              " 'split2_test_score': array([-0.16872236, -0.16838709, -0.16994499, -0.16894777, -0.16946546,\n",
              "        -0.1697488 , -0.16985403, -0.16993397, -0.16958602, -0.16878023,\n",
              "        -0.16919908, -0.16885879, -0.16933543, -0.16886208, -0.1696146 ,\n",
              "        -0.16846812, -0.17089331, -0.16857555, -0.16941906, -0.16892085,\n",
              "        -0.16912795, -0.16912886, -0.1693244 , -0.16867578, -0.16963548,\n",
              "        -0.16845023, -0.17002182, -0.16937045, -0.16922219, -0.16906634,\n",
              "        -0.17032055, -0.17015441]),\n",
              " 'split3_test_score': array([-0.19531809, -0.19346385, -0.19849376, -0.19719986, -0.19505835,\n",
              "        -0.19598039, -0.19632722, -0.19306954, -0.19498165, -0.19440193,\n",
              "        -0.19549902, -0.1975595 , -0.19148346, -0.19660622, -0.19450108,\n",
              "        -0.19493745, -0.19465469, -0.19296091, -0.19511744, -0.20024425,\n",
              "        -0.19303864, -0.19520503, -0.1982251 , -0.1998437 , -0.19451544,\n",
              "        -0.19240741, -0.1942289 , -0.19705109, -0.19637026, -0.19770744,\n",
              "        -0.19612497, -0.19557789]),\n",
              " 'std_fit_time': array([22.32332316,  0.62067224,  0.4616905 ,  0.50007303,  0.46581067,\n",
              "         2.98550326,  3.20891627,  0.18801934,  0.39535551,  0.75768847,\n",
              "         1.60870719,  1.29460563,  0.97882678,  0.7958489 ,  0.72995304,\n",
              "         0.55167201, 18.08219647,  0.61409182, 17.00049084, 16.92864544,\n",
              "         0.84924934, 17.11877853,  0.84501241,  1.3860608 , 18.60253505,\n",
              "        15.6629594 , 15.41745343, 14.97983233, 15.14197227, 17.70211773,\n",
              "        15.11631953, 15.3509352 ]),\n",
              " 'std_score_time': array([0.08847175, 0.01573413, 0.05365117, 0.3011439 , 0.05857107,\n",
              "        0.08917923, 0.05291128, 0.05112248, 0.03475326, 0.06033292,\n",
              "        0.03229925, 0.06167774, 0.34780441, 0.23913508, 0.0708955 ,\n",
              "        0.05315591, 0.05574858, 0.19725424, 0.10891573, 0.06110521,\n",
              "        0.08688611, 0.04969115, 0.05576621, 0.05958542, 0.09220472,\n",
              "        0.03815095, 0.01959336, 0.25631048, 0.06009965, 0.03369584,\n",
              "        0.30102931, 0.03328061]),\n",
              " 'std_test_score': array([0.01438463, 0.01468349, 0.01605669, 0.0157552 , 0.0146295 ,\n",
              "        0.01490755, 0.01592466, 0.01416974, 0.0142841 , 0.01409239,\n",
              "        0.01511454, 0.01563394, 0.01289041, 0.0150135 , 0.01430862,\n",
              "        0.01474984, 0.01459328, 0.01354372, 0.01462663, 0.01654907,\n",
              "        0.01357661, 0.01460561, 0.01588455, 0.01624635, 0.0145557 ,\n",
              "        0.01345465, 0.01427369, 0.01559855, 0.01531252, 0.01533853,\n",
              "        0.01523678, 0.01483341])}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.cv_results_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
